{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHij2opWyKL7",
        "outputId": "79fffedc-dd77-4224-d4c6-7034bb5630b4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9eSEdMLcyz2f"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "import pandas as pd\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "df=pd.read_csv('/content/lyrics_10k.csv')\n",
        "def clean_text(text, max_length=578):\n",
        "    cleaned_text = ' '.join(text.split())\n",
        "    #print(cleaned\n",
        "    cleaned_text = cleaned_text.lower()\n",
        "    cleaned_text = cleaned_text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "    #print(cleaned_text)\n",
        "    cleaned_text = ''.join([i for i in cleaned_text if not i.isdigit()])\n",
        "    #print(cleaned_text)\n",
        "    cleaned_text = ''.join([i for i in cleaned_text if i.isalpha() or i.isspace()])\n",
        "    #print(cleaned_text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    word_tokens = word_tokenize(cleaned_text)\n",
        "    cleaned_text = ' '.join([word for word in word_tokens if word.lower() not in stop_words])\n",
        "    #print(cleaned_text)\n",
        "    if len(cleaned_text) > max_length:\n",
        "        cleaned_text = cleaned_text[:max_length]\n",
        "    else:\n",
        "        cleaned_text = cleaned_text.ljust(max_length)\n",
        "    #print(cleaned_text)\n",
        "    return cleaned_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNp--DlJ1Etd"
      },
      "outputs": [],
      "source": [
        "df['cleaned_lyrics'] = df['lyrics'].apply(clean_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rjLtnitI1K2g",
        "outputId": "0e3d4740-1d15-4791-ea00-ee4d3d0f793c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                         cleaned_lyrics  emotion\n",
            "0     better home lyrics feel body breathing feel he...     fear\n",
            "1     illusions lyrics people tell need help people ...    anger\n",
            "2     touching ground lyrics swear touched saw heave...     love\n",
            "3     nothing stopping lyrics nothing stopping stopp...      joy\n",
            "4     shall believe lyrics come lay hands even lie s...  sadness\n",
            "...                                                 ...      ...\n",
            "8669  neon forest lyrics im sliding like lizard bell...     love\n",
            "8670  harambe lyrics mafia billboard hitmakers yeah ...      joy\n",
            "8671  lyrics seems like dreams like ive always could...      joy\n",
            "8672  translations türkçe español selena gomez fun f...    anger\n",
            "8673  translations türkçe português english english ...      joy\n",
            "\n",
            "[8674 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "\n",
        "# Load the model and tokenizer\n",
        "model_name = 'bhadresh-savani/distilbert-base-uncased-emotion'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "# Initialize the emotion detection pipeline with truncation\n",
        "emotion_detection = pipeline(\n",
        "    'text-classification',\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=512,\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "# Apply emotion detection to the cleaned lyrics\n",
        "df['emotion'] = df['cleaned_lyrics'].apply(lambda x: emotion_detection(x)[0]['label'])\n",
        "print(df[['cleaned_lyrics', 'emotion']])\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}